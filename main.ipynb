{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86ddc4a1",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df963393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tempfile\n",
    "from pydub import AudioSegment\n",
    "from moviepy import VideoFileClip\n",
    "\n",
    "import librosa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb792a27",
   "metadata": {},
   "source": [
    "### Function: `block_difference`\n",
    "- Compares two frames by dividing them into blocks\n",
    "- Calculates the mean absolute difference between corresponding blocks \n",
    "- Returns the average block difference across the whole frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a03d719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_difference(frame1, frame2, block_size=16):\n",
    "    height, width = frame1.shape\n",
    "    total_diff = 0\n",
    "    num_blocks = 0\n",
    "\n",
    "    for y in range(0, height, block_size):\n",
    "        for x in range(0, width, block_size):\n",
    "            block1 = frame1[y:y+block_size, x:x+block_size]\n",
    "            block2 = frame2[y:y+block_size, x:x+block_size]\n",
    "            if block1.shape == block2.shape:\n",
    "                diff = np.abs(block1.astype(int) - block2.astype(int)).mean()\n",
    "                total_diff += diff\n",
    "                num_blocks += 1\n",
    "\n",
    "    return total_diff / num_blocks if num_blocks > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27bedcd",
   "metadata": {},
   "source": [
    "### Function: `extract_keyframes_from_shot`\n",
    "- Extracts keyframes from a list of frames using block difference\n",
    "- Uses the first frame as reference, then adds new frames when difference exceeds a threshold\n",
    "- Resizes keyframes to 224x224\n",
    "- Ensures exactly 15 keyframes by padding with the last frame if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24e9dc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keyframes_from_shot(frames, fps, block_threshold=20):\n",
    "    duration = len(frames) / fps\n",
    "    target_num_keyframes = 15\n",
    "    keyframes = []\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        return []\n",
    "\n",
    "    ref_gray = cv2.cvtColor(frames[0], cv2.COLOR_BGR2GRAY)\n",
    "    resized_frame = cv2.resize(frames[0], (224, 224))\n",
    "    keyframes.append(resized_frame)\n",
    "\n",
    "    for i, frame in enumerate(frames[1:], start=1):\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        diff = block_difference(ref_gray, gray)\n",
    "        if diff > block_threshold:\n",
    "            resized = cv2.resize(frame, (224, 224))\n",
    "            keyframes.append(resized)\n",
    "\n",
    "        if len(keyframes) >= target_num_keyframes:\n",
    "            break\n",
    "\n",
    "    while len(keyframes) < target_num_keyframes:\n",
    "        keyframes.append(keyframes[-1].copy())\n",
    "\n",
    "    return keyframes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e08affc",
   "metadata": {},
   "source": [
    "### Function: `extract_audio_shot`\n",
    "- Extracts a segment of audio from a given audio file\n",
    "- Takes `start_time` and `end_time` in seconds\n",
    "- Saves the extracted audio segment as a `.wav` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56fea99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_shot(audio_path, start_time, end_time, save_path):\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    start_ms = int(start_time * 1000)\n",
    "    end_ms = int(end_time * 1000)\n",
    "    segment = audio[start_ms:end_ms]\n",
    "    segment.export(save_path, format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a90adc9",
   "metadata": {},
   "source": [
    "### Function: `extract_audio_temp`\n",
    "- Extracts the entire audio track from a video\n",
    "- Saves it temporarily as a `.wav` file\n",
    "- Returns the path of the temporary audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62baec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_temp(video_path):\n",
    "    video = VideoFileClip(video_path)\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as temp_audio_file:\n",
    "        temp_audio_path = temp_audio_file.name\n",
    "    video.audio.write_audiofile(temp_audio_path)\n",
    "    return temp_audio_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5db51a5",
   "metadata": {},
   "source": [
    "### Function: `extract_shots_and_keyframes_with_audio`\n",
    "- Splits a video into shots based on histogram difference\n",
    "- Extracts **keyframes** from each shot using block difference\n",
    "- Saves the **corresponding audio segment** of each shot as `.wav`\n",
    "- Returns a list of samples, where each sample contains:  \n",
    "  - keyframes  \n",
    "  - audio file path  \n",
    "  - start time and end time of the shot  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11562f83",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0a6e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_shots_and_keyframes_with_audio(video_path, hist_threshold=30, block_threshold=20, fps_cap=30, save_audio_dir=\"audio_shots\"):\n",
    "    os.makedirs(save_audio_dir, exist_ok=True)\n",
    "\n",
    "    audio_path = extract_audio_temp(video_path)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    fps = min(fps, fps_cap)\n",
    "\n",
    "    prev_hist = None\n",
    "    frames = []\n",
    "    all_samples = []\n",
    "    shot_start_frame = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        hist = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
    "        hist = cv2.normalize(hist, hist).flatten()\n",
    "\n",
    "        if prev_hist is not None:\n",
    "            diff = cv2.compareHist(prev_hist, hist, cv2.HISTCMP_BHATTACHARYYA)\n",
    "            if diff > hist_threshold / 100:\n",
    "                shot_end_frame = shot_start_frame + len(frames)\n",
    "                start_time = shot_start_frame / fps\n",
    "                end_time = shot_end_frame / fps\n",
    "\n",
    "                keyframes = extract_keyframes_from_shot(frames, fps, block_threshold)\n",
    "\n",
    "                if keyframes:\n",
    "                    audio_filename = f\"{os.path.basename(video_path)}_{int(start_time*1000)}_{int(end_time*1000)}.wav\"\n",
    "                    audio_save_path = os.path.join(save_audio_dir, audio_filename)\n",
    "                    extract_audio_shot(audio_path, start_time, end_time, audio_save_path)\n",
    "\n",
    "                    all_samples.append({\n",
    "                        \"keyframes\": keyframes,\n",
    "                        \"audio_path\": audio_save_path,\n",
    "                        \"start_time\": start_time,\n",
    "                        \"end_time\": end_time\n",
    "                    })\n",
    "\n",
    "                shot_start_frame = shot_end_frame\n",
    "                frames = []\n",
    "\n",
    "        frames.append(frame.copy())\n",
    "        prev_hist = hist\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    os.remove(audio_path)\n",
    "\n",
    "    return all_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2c7fe9",
   "metadata": {},
   "source": [
    "### Function: `process_category_folder`\n",
    "Processes all video files in a category folder, extracts shots with keyframes and audio, and assigns the given label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c062407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_category_folder(category_path, audio_folder_path, label):\n",
    "    samples = []\n",
    "\n",
    "    for filename in os.listdir(category_path):\n",
    "        if filename.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "            video_path = os.path.join(category_path, filename)\n",
    "            audio_path = os.path.join(audio_folder_path, os.path.splitext(filename)[0] + \".wav\")\n",
    "            print(f\"Processing: {video_path}\")\n",
    "            shot_samples = extract_shots_and_keyframes_with_audio(video_path)\n",
    "            for sample in shot_samples:\n",
    "                sample[\"label\"] = label\n",
    "                samples.append(sample)\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95665406",
   "metadata": {},
   "source": [
    "### Main Script\n",
    "Iterates over all categories, processes their videos, and collects all samples into a single list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = r\"C:\\Users\\LEGION\\Desktop\\Violence Detection-PyTorch\"\n",
    "categories = [\"bloody\", \"explosions\", \"fight\", \"non-violence\"]\n",
    "\n",
    "all_samples = []\n",
    "\n",
    "for category in categories:\n",
    "    video_folder = os.path.join(base_path, category)\n",
    "    audio_folder = os.path.join(base_path, category)\n",
    "    category_samples = process_category_folder(video_folder, audio_folder, category)\n",
    "    all_samples.extend(category_samples)\n",
    "\n",
    "print(\"Total samples:\", len(all_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b51b78",
   "metadata": {},
   "source": [
    "### Data Preparation (Images + Audio + Labels)\n",
    "\n",
    "- Initializes empty lists for **image sequences**, **audio spectrograms**, and **labels**\n",
    "- Ensures each sample has exactly **15 frames** (by truncating or padding with the last frame)\n",
    "- Loads the corresponding **audio clip**, converts it into a **mel-spectrogram (128 mel bins)**, and pads/truncates it to a fixed length of **200 time steps**\n",
    "- Appends processed image frames, spectrogram, and label to their lists\n",
    "- Encodes labels into numeric form using `LabelEncoder`\n",
    "- Converts all lists into NumPy arrays and prints their shapes for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e04e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_images = []\n",
    "X_audio = []\n",
    "y_labels = []\n",
    "\n",
    "time_steps = 15\n",
    "mel_bins = 128\n",
    "max_audio_len = 200\n",
    "\n",
    "for sample in all_samples:\n",
    "    frames = sample[\"keyframes\"]\n",
    "    if len(frames) < time_steps:\n",
    "        frames += [frames[-1]] * (time_steps - len(frames))\n",
    "    else:\n",
    "        frames = frames[:time_steps]\n",
    "\n",
    "    y_audio, sr = librosa.load(sample[\"audio_path\"], sr=22050)\n",
    "    mel = librosa.feature.melspectrogram(y=y_audio, sr=sr, n_mels=mel_bins)\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "\n",
    "    if mel_db.shape[1] < max_audio_len:\n",
    "        pad_width = max_audio_len - mel_db.shape[1]\n",
    "        mel_db = np.pad(mel_db, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        mel_db = mel_db[:, :max_audio_len]\n",
    "\n",
    "    X_images.append(np.array(frames))\n",
    "    X_audio.append(mel_db)\n",
    "    y_labels.append(sample[\"label\"])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y_labels)\n",
    "\n",
    "X_images = np.array(X_images)\n",
    "X_audio = np.array(X_audio)\n",
    "y_encoded = np.array(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fd8bdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# joblib.dump(encoder, \"label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a262e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_img_train, X_img_test, X_audio_train, X_audio_test, y_train, y_test = train_test_split(\n",
    "    X_images, X_audio, y_encoded,\n",
    "    test_size=0.15,\n",
    "    stratify=y_encoded,\n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "905ff313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"train_data_with_audio_short.pkl\", \"wb\") as f:\n",
    "#     pickle.dump((X_img_train, X_audio_train, y_train), f)\n",
    "\n",
    "# with open(\"test_data_with_audio_short.pkl\", \"wb\") as f:\n",
    "#     pickle.dump((X_img_test, X_audio_test, y_test), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf1c384",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_data_with_audio_short.pkl\", \"rb\") as f:\n",
    "    X_img_train, X_audio_train, y_train = pickle.load(f)\n",
    "\n",
    "with open(\"test_data_with_audio_short.pkl\", \"rb\") as f:\n",
    "    X_img_test, X_audio_test, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caed5fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
